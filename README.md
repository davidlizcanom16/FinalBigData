# ğŸ›ï¸ E-commerce Price Prediction Dashboard

Dashboard de anÃ¡lisis predictivo de precios en tiempo real usando Azure Cosmos DB y Machine Learning.

## ğŸŒ Demo en Vivo

**Dashboard:** [https://tu-app.streamlit.app](https://tu-app.streamlit.app) *(se actualizarÃ¡ despuÃ©s del deploy)*

## âœ¨ CaracterÃ­sticas

- â˜ï¸ **Base de datos en la nube**: Azure Cosmos DB con MongoDB API
- ğŸ¤– **3 Modelos de ML**: Random Forest, Gradient Boosting, Neural Network
- ğŸ“Š **Dashboard interactivo**: Streamlit con actualizaciÃ³n automÃ¡tica cada 60s
- ğŸ”„ **RecolecciÃ³n automÃ¡tica**: GitHub Actions ejecuta cada 5 minutos
- ğŸ“ˆ **Visualizaciones**: GrÃ¡ficos interactivos con Plotly

## ğŸ¯ Resultados de los Modelos

| Modelo | Test MAE | Test RÂ² |
|--------|----------|---------|
| Random Forest | $12.82 | 0.9892 |
| Gradient Boosting | $11.28 | 0.9917 |
| Neural Network | $37.86 | 0.9441 |

## ğŸš€ Despliegue (Recomendado)

El proyecto estÃ¡ configurado para desplegarse automÃ¡ticamente:

1. **Fork este repositorio**
2. **Configura secretos en GitHub**:
   - Ve a Settings â†’ Secrets â†’ Actions
   - Agrega: `COSMOS_CONNECTION_STRING` con tu connection string de Azure
3. **Despliega en Streamlit Cloud**:
   - Ve a [share.streamlit.io](https://share.streamlit.io)
   - Conecta tu GitHub
   - Selecciona el repo y `dashboard.py`
   - Agrega el secret: `COSMOS_CONNECTION_STRING`

El dashboard estarÃ¡ disponible 24/7 y los datos se recolectarÃ¡n automÃ¡ticamente cada 5 minutos.

## ğŸ’» InstalaciÃ³n Local

Si prefieres ejecutarlo localmente:

### Prerequisitos
- Python 3.12+
- Cuenta de Azure con Cosmos DB

### Pasos
```bash
# 1. Clonar repositorio
git clone https://github.com/tu-usuario/ecommerce-price-prediction.git
cd ecommerce-price-prediction

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar variables de entorno
cp .env.example .env
# Edita .env y agrega tu COSMOS_CONNECTION_STRING

# 4. Ejecutar dashboard
streamlit run dashboard.py
```

### RecolecciÃ³n manual de datos
```bash
# Recolectar datos una vez
python data_collector.py

# RecolecciÃ³n automÃ¡tica continua
python auto_collector.py
```

## ğŸ“ Estructura del Proyecto
```
ecommerce-price-prediction/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ auto_collector.yml    # GitHub Actions para recolecciÃ³n
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml              # ConfiguraciÃ³n de Streamlit
â”œâ”€â”€ dashboard.py                  # ğŸ“Š Dashboard principal
â”œâ”€â”€ models.py                     # ğŸ¤– Modelos de ML
â”œâ”€â”€ data_collector.py             # ğŸ“¡ Recolector de datos
â”œâ”€â”€ azure_connector.py            # â˜ï¸ Conector a Azure
â”œâ”€â”€ auto_collector.py             # ğŸ”„ RecolecciÃ³n automÃ¡tica
â”œâ”€â”€ requirements.txt              # ğŸ“¦ Dependencias
â”œâ”€â”€ .env.example                  # ğŸ” Template de variables
â”œâ”€â”€ .gitignore                   # ğŸš« Archivos ignorados
â””â”€â”€ README.md                     # ğŸ“– Este archivo
```

## ğŸ—ï¸ Arquitectura
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fake Store API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Actions  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Azure Cosmos DB  â”‚
â”‚ (cada 5 min)    â”‚      â”‚   (MongoDB API)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Streamlit Cloud  â”‚
                         â”‚   (Dashboard)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” ConfiguraciÃ³n de Azure

1. Crear cuenta en [Azure Portal](https://portal.azure.com)
2. Crear Azure Cosmos DB con MongoDB API
3. Seleccionar modo "Serverless" (gratis)
4. Copiar la Connection String
5. Agregar a `.env` o como secret en GitHub/Streamlit

## ğŸ“Š Uso del Dashboard

El dashboard tiene 4 secciones:

1. **ğŸ“Š Dashboard Principal**: KPIs y visualizaciones generales
2. **ğŸ¤– PredicciÃ³n de Precios**: PredicciÃ³n interactiva con los 3 modelos
3. **ğŸ“ˆ AnÃ¡lisis de Modelos**: ComparaciÃ³n y mÃ©tricas de rendimiento
4. **ğŸ“‹ Datos en Tiempo Real**: ExploraciÃ³n de datos con filtros

## ğŸ“ Contexto AcadÃ©mico

**Proyecto 2**: Cloud Document Database with Predictive Analytics

**Requisitos cumplidos:**
- âœ… Base de datos NoSQL en Azure
- âœ… 3+ modelos predictivos (incluyendo red neuronal)
- âœ… Dashboard interactivo
- âœ… ConexiÃ³n en tiempo real a base de datos en la nube
- âœ… DocumentaciÃ³n completa
- âœ… PresentaciÃ³n profesional

## ğŸ¤ Contribuir

Si quieres contribuir:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“ Licencia

MIT License - libre para uso acadÃ©mico y comercial

## ğŸ‘¤ Autor

**Vanessa Lizcano**

Proyecto desarrollado para el curso de Cloud Computing
Universidad [Tu Universidad] - 2024

---

â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub
```

---

### 19.5 Actualizar `.gitignore`
```
# Archivos de entorno
.env

# Archivos de datos temporales
datos_ecommerce.json
*.log
collector.log

# Python
__pycache__/
*.py[cod]
*$py.class
*.so

# Jupyter Notebook
.ipynb_checkpoints

# IDEs
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Outputs
model_comparison.png
*.pkl
```

---

## ğŸ“¦ Estructura Final de Archivos

Tu proyecto debe tener:
```
ProyectoAzure/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ auto_collector.yml
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml
â”œâ”€â”€ dashboard.py
â”œâ”€â”€ models.py
â”œâ”€â”€ data_collector.py
â”œâ”€â”€ azure_connector.py
â”œâ”€â”€ auto_collector.py
â”œâ”€â”€ test_api.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env (NO subir a GitHub)
â”œâ”€â”€ .env.example (SÃ subir)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
